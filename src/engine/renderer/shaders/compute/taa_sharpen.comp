#version 450
#extension GL_ARB_separate_shader_objects : enable
#extension GL_ARB_shading_language_420pack : enable

// TAA Sharpening Compute Shader
// Applies sharpening filter to reduce temporal blur from TAA

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

// Input texture (TAA resolved image)
layout(set = 0, binding = 0) uniform sampler2D inputImage;

// Output image
layout(set = 0, binding = 1, rgba8) uniform image2D outputImage;

// Sharpening parameters
layout(set = 0, binding = 2) uniform SharpenParams {
    vec4 params; // x: sharpness, y: edge threshold, z: center weight, w: unused
    vec2 resolution;
    vec2 invResolution;
} sharpen;

// Luma function for edge detection
float getLuma(vec3 color) {
    return dot(color, vec3(0.299, 0.587, 0.114));
}

// Adaptive sharpening based on local contrast
float getAdaptiveSharpness(float centerLuma, float neighborLuma) {
    float contrast = abs(centerLuma - neighborLuma);
    // Reduce sharpening in low contrast areas to avoid noise amplification
    return mix(sharpen.params.x * 0.5, sharpen.params.x, 
               smoothstep(0.0, sharpen.params.y, contrast));
}

void main() {
    ivec2 coords = ivec2(gl_GlobalInvocationID.xy);
    
    // Check bounds
    if (coords.x >= sharpen.resolution.x || coords.y >= sharpen.resolution.y) {
        return;
    }
    
    vec2 uv = (vec2(coords) + 0.5) * sharpen.invResolution;
    
    // Sample center pixel
    vec3 center = texture(inputImage, uv).rgb;
    float centerLuma = getLuma(center);
    
    // Sample neighborhood for sharpening kernel
    vec3 top    = texture(inputImage, uv + vec2( 0.0, -sharpen.invResolution.y)).rgb;
    vec3 bottom = texture(inputImage, uv + vec2( 0.0,  sharpen.invResolution.y)).rgb;
    vec3 left   = texture(inputImage, uv + vec2(-sharpen.invResolution.x,  0.0)).rgb;
    vec3 right  = texture(inputImage, uv + vec2( sharpen.invResolution.x,  0.0)).rgb;
    
    // Calculate neighbor average for contrast detection
    vec3 neighbors = (top + bottom + left + right) * 0.25;
    float neighborLuma = getLuma(neighbors);
    
    // Adaptive sharpness based on local contrast
    float adaptiveSharpness = getAdaptiveSharpness(centerLuma, neighborLuma);
    
    // Apply sharpening using unsharp mask
    // Result = Original + Sharpness * (Original - Blurred)
    vec3 sharpened = center + adaptiveSharpness * (center - neighbors);
    
    // Optional: Apply more sophisticated sharpening with diagonal samples
    if (sharpen.params.z > 0.5) {
        // Sample diagonals for better edge preservation
        vec3 topLeft     = texture(inputImage, uv + vec2(-sharpen.invResolution.x, -sharpen.invResolution.y)).rgb;
        vec3 topRight    = texture(inputImage, uv + vec2( sharpen.invResolution.x, -sharpen.invResolution.y)).rgb;
        vec3 bottomLeft  = texture(inputImage, uv + vec2(-sharpen.invResolution.x,  sharpen.invResolution.y)).rgb;
        vec3 bottomRight = texture(inputImage, uv + vec2( sharpen.invResolution.x,  sharpen.invResolution.y)).rgb;
        
        // 9-tap kernel with center weight
        vec3 allNeighbors = (top + bottom + left + right) * 0.125 + 
                           (topLeft + topRight + bottomLeft + bottomRight) * 0.0625;
        
        // Recalculate with full neighborhood
        float allNeighborLuma = getLuma(allNeighbors);
        float edgeStrength = abs(centerLuma - allNeighborLuma);
        
        // Stronger sharpening for edges, weaker for smooth areas
        float edgeSharpness = mix(adaptiveSharpness * 0.7, adaptiveSharpness * 1.3,
                                  smoothstep(0.05, 0.2, edgeStrength));
        
        sharpened = center + edgeSharpness * (center - allNeighbors);
    }
    
    // Clamp to avoid overflow/underflow
    sharpened = clamp(sharpened, vec3(0.0), vec3(1.0));
    
    // Store result
    imageStore(outputImage, coords, vec4(sharpened, 1.0));
}